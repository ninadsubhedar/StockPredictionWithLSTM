{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Feed Scrapper and Sentimental Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "This notebook deals with fetching tweets from twitter feed using a Library called GetOldTweet3. We will be using this library because the standard API for twitter has limitations to fetch data for just previous 7 days. But as we will need to pull data from a previous timeline we will have to use this scraper. We will use TextBlob library that allows us to check for the sentimental polarity of any text, in our case it will be tweets. We can then bundle all of this data and use it for building a Neural network model with twitter feed as an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "import datetime as dt\n",
    "import pickle\n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take the timestamp from the stocks data. For each day we can take a small sample of tweets and then calculate the scure of each tweet. Once we have that we can take an aggregate for that day. This new score will be the twitte rscore for that day's stock price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>120.74</td>\n",
       "      <td>121.36</td>\n",
       "      <td>118.60</td>\n",
       "      <td>118.63</td>\n",
       "      <td>4913977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>118.99</td>\n",
       "      <td>120.80</td>\n",
       "      <td>118.63</td>\n",
       "      <td>119.87</td>\n",
       "      <td>4440672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>119.65</td>\n",
       "      <td>119.99</td>\n",
       "      <td>118.80</td>\n",
       "      <td>118.81</td>\n",
       "      <td>4627478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>121.10</td>\n",
       "      <td>121.48</td>\n",
       "      <td>119.53</td>\n",
       "      <td>119.71</td>\n",
       "      <td>4006838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>120.77</td>\n",
       "      <td>121.04</td>\n",
       "      <td>119.80</td>\n",
       "      <td>120.90</td>\n",
       "      <td>3721345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp    open    high     low   close   volume\n",
       "0  2019-07-19  120.74  121.36  118.60  118.63  4913977\n",
       "1  2019-07-18  118.99  120.80  118.63  119.87  4440672\n",
       "2  2019-07-17  119.65  119.99  118.80  118.81  4627478\n",
       "3  2019-07-16  121.10  121.48  119.53  119.71  4006838\n",
       "4  2019-07-15  120.77  121.04  119.80  120.90  3721345"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"daily_PYPL.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take the timestamps starting from the index 50 because for the first 50 entries in stock data will be used as an input for the next days stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['timestamp'][50:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to load the tweets data if it is already saved or else we scrape the data from twitter feed. The parameters fro the scraper would be the timestamp and the twitter search query.\n",
    "In our case we use `$PYPL` for the search query. This is because in twitter all stock related data is tagges using the `$` symbol followed by the stock short name. We perform this for each timestamp in our stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Saved Tweets\n",
      "Tweets Data Loaded\n"
     ]
    }
   ],
   "source": [
    "all_tweets = []\n",
    "\n",
    "try:\n",
    "    print('Loading Saved Tweets')\n",
    "    all_tweets = pickle.load(open('tweets.data', 'rb'))\n",
    "except (OSError, IOError) as e:\n",
    "    print('No Tweets found. Downloading Tweets')\n",
    "    for d in df:\n",
    "        fromDate = d\n",
    "        toDate = dt.datetime.strptime(d, '%Y-%m-%d') + dt.timedelta(days=1)\n",
    "        toDate = dt.datetime.strftime(toDate,'%Y-%m-%d')\n",
    "        #print(fromDate+\" \"+toDate)\n",
    "        tweetCriteria = got.manager.TweetCriteria().setQuerySearch('$PYPL').setSince(fromDate).setUntil(toDate).setMaxTweets(5)\n",
    "        tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "        print(\"Downloaded Tweets for date:\" + fromDate)\n",
    "        all_tweets.append(tweets)\n",
    "    print('Saving Tweets')\n",
    "    pickle.dump(all_tweets,open('tweets.data', 'wb'))\n",
    "print('Tweets Data Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the tweets we can apply the TextBlob library to get the sentimental polarity/score for the each tweet. And then we aggregate them to get the score for that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for entry in all_tweets:\n",
    "    score = 0\n",
    "    for tweet in entry:\n",
    "        blob = TextBlob(tweet.text)\n",
    "        score = score + blob.sentiment.polarity\n",
    "    scores.append(score/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving score using pickle library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Scores\n"
     ]
    }
   ],
   "source": [
    "print('Saving Scores')\n",
    "pickle.dump(scores,open('tweetScore.data','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a data frame to save all the data to a CSV file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = []\n",
    "tweet_score = []\n",
    "for entry in all_tweets:\n",
    "    for tweet in entry:\n",
    "        tweet_text.append(tweet.text)\n",
    "        blob = TextBlob(tweet.text)\n",
    "        tweet_score.append(blob.sentiment.polarity)\n",
    "\n",
    "dict = {'Tweets':tweet_text,'Score':tweet_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>IBD Big Cap 20 Ranked May 8, 2019 1. $VEEV $IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>OptionAlarm provides Option Swing Trade Alerts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>http://bit.ly/2Uh4tyu Tim Sykes Alerts REVEALE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3750</td>\n",
       "      <td>$PYPL $FB: Facebook’s crypto project echoes bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>I do not like the current situations BUT this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Score                                             Tweets\n",
       "0  0.0000  IBD Big Cap 20 Ranked May 8, 2019 1. $VEEV $IN...\n",
       "1  0.4375  OptionAlarm provides Option Swing Trade Alerts...\n",
       "2  0.0000  http://bit.ly/2Uh4tyu Tim Sykes Alerts REVEALE...\n",
       "3  0.3750  $PYPL $FB: Facebook’s crypto project echoes bo...\n",
       "4  0.0000  I do not like the current situations BUT this ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('twitter_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We have extracted sample data from the twitter feed and converted that to a sentimental score. This score can be now used as an input to the Neural Network for predicting stock price based on twitter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution:\n",
    "1. Code contributed by me ~ 80%\n",
    "2. Code taken from documentations: ~20%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations:\n",
    "1. https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis\n",
    "2. https://github.com/Mottl/GetOldTweets3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "MIT License \n",
    "\n",
    "Copyright (c) 2019 Ninad Subhedar \n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: \n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. \n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
